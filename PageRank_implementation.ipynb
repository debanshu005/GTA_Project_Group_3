{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PageRank_implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RvJy5XnGmna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45658c8-75b7-4bcf-b482-fe090d52f99e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.028205852722366004,\n",
              " 1: 0.012967526997010365,\n",
              " 2: 0.012757941807435356,\n",
              " 3: 0.012563350995735635,\n",
              " 4: 0.012963195819012695,\n",
              " 5: 0.012346278103426275,\n",
              " 6: 0.01316842373953849,\n",
              " 7: 0.013175203598245182,\n",
              " 8: 0.012588237553065077,\n",
              " 9: 0.012165442681689346,\n",
              " 10: 0.01255937373666854,\n",
              " 11: 0.013567388066723626,\n",
              " 12: 0.01337910004834656,\n",
              " 13: 0.01256499899211665,\n",
              " 14: 0.012954791941095894,\n",
              " 15: 0.013364310640092065,\n",
              " 16: 0.012953845853879518,\n",
              " 17: 0.013370381317742187,\n",
              " 18: 0.012950231792749938,\n",
              " 19: 0.012760221402946137,\n",
              " 20: 0.012970500829701831,\n",
              " 21: 0.01316772798256506,\n",
              " 22: 0.013564836955451328,\n",
              " 23: 0.013162706059675356,\n",
              " 24: 0.013162706059675356,\n",
              " 25: 0.01296991732959068,\n",
              " 26: 0.013163153252240902,\n",
              " 27: 0.012964877344617255,\n",
              " 28: 0.0137720663641206,\n",
              " 29: 0.012546464818214408,\n",
              " 30: 0.012950231792749938,\n",
              " 31: 0.011564253847083261,\n",
              " 32: 0.012384100853896476,\n",
              " 33: 0.012762420939245548,\n",
              " 34: 0.013162111247458669,\n",
              " 35: 0.013375927130140144,\n",
              " 36: 0.012553242475474322,\n",
              " 37: 0.012969368927226093,\n",
              " 38: 0.011782397828298893,\n",
              " 39: 0.013564836955451328,\n",
              " 40: 0.013569617827077591,\n",
              " 41: 0.013158626581839767,\n",
              " 42: 0.027585918877910377,\n",
              " 43: 0.02747112382170353,\n",
              " 44: 0.026789156348832,\n",
              " 45: 0.026723318133183856,\n",
              " 46: 0.025917651986601176,\n",
              " 47: 0.025791591435021667,\n",
              " 48: 0.025534484398659525,\n",
              " 49: 0.025114721832969953,\n",
              " 50: 0.024669133162334392,\n",
              " 51: 0.024268530193923207,\n",
              " 52: 0.023832195567774984,\n",
              " 53: 0.023860914567294212,\n",
              " 54: 0.023280940830959614,\n",
              " 55: 0.02303716413466817,\n",
              " 56: 0.02238715437151857,\n",
              " 57: 0.02200240502916228,\n",
              " 58: 0.021758614524522622,\n",
              " 59: 0.021406789571279596}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def PageRank(G, #A NetworkX directed graph and if G is an undirected graph \n",
        "             #then it is converted to directed graph by two directed edges with different direction\n",
        "             d=0.85, #damping parameter for PageRank, we took d=0.85\n",
        "             dict_key=None, #consists a dictionary with a key for every graph  \n",
        "             max_iter=120, #maximum number of iterations for power method for eigenvalue solver\n",
        "             tolerance=1.0e-6, #Error tolerance for checking convergence in power method solver\n",
        "             init_val=None, # Initial value of PageRank iteration which is constant for all web pages\n",
        "             weight= 'weight', # Edge data key to use as weight. Weight will be 1 if weight is None\n",
        "             dang=None # Nodes without out edges\n",
        "             ):\n",
        "  if not G.is_directed():\n",
        "    H=G.to_directed()\n",
        "  else:\n",
        "    H=G\n",
        "  if len(G)==0:\n",
        "    return {}\n",
        "  \n",
        "  #Creating a copy of H in right stochastic form\n",
        "  S=nx.stochastic_graph(H, weight=weight)\n",
        "  n = W.number_of_nodes()\n",
        "\n",
        "  #Choosing a initial vector\n",
        "  if init_val is None:\n",
        "        u = dict.fromkeys(S, 1.0 / n)\n",
        "  else:\n",
        "        # Normalizing initial vector\n",
        "        w = float(sum(init_val.values()))\n",
        "        x = dict((i, v / w) for i, v in init_val.items())\n",
        " \n",
        "  if dict_key is None:\n",
        " \n",
        "        # Assigning uniform personalization vector\n",
        "        p = dict.fromkeys(S, 1.0 / n)\n",
        "  else:\n",
        "        missing = set(G) - set(dict_key)\n",
        "        if missing:\n",
        "            raise NetworkXError('Dictionary key dictionary '\n",
        "                                'must have a value assigned for every node. '\n",
        "                                'Missing nodes is/are %s' % missing)\n",
        "        w = float(sum(dict_key.values()))\n",
        "        p = dict((i, v / w) for i, v in dict_key.items())\n",
        "\n",
        "\n",
        "  if dang is None:\n",
        " \n",
        "        # Use dictionary key vector if dangling vector not given\n",
        "        dang_w = p\n",
        "  else:\n",
        "        missing = set(G) - set(dang)\n",
        "        if missing:\n",
        "            raise NetworkXError('Dangling node dictionary '\n",
        "                                'must have a value assigned for every node. '\n",
        "                                'Missing nodes %s' % missing)\n",
        "        w = float(sum(dang.values()))\n",
        "        dang_w = dict((i, v/w) for i, v in dang.items())\n",
        "  dang_n = [m for m in S if S.out_degree(m, weight=weight) == 0.0]\n",
        "\n",
        "\n",
        "    # power iteration for eigen vector calculation: up to max_iter\n",
        "  for _ in range(max_iter):\n",
        "        x_l = u\n",
        "        u = dict.fromkeys(x_l.keys(), 0)\n",
        "        d_sum = d * sum(x_l[m] for m in dang_n)\n",
        "        for m in u:\n",
        " \n",
        "            # multiply x^T=xlast^T*W\n",
        "            for j in S[m]:\n",
        "                u[j] += d * x_l[m] * S[m][j][weight]\n",
        "            u[m] += dang_s * dang_w[m] + (1.0 - d) * p[m]\n",
        " \n",
        "        # check convergence, l1 norm\n",
        "        error = sum([abs(u[m] - x_l[m]) for m in u])\n",
        "        if error < n*tolerance:\n",
        "            return u\n",
        "  raise NetworkXError('PageRank: Power iteration failed to converge '\n",
        "                        'in %d iterations.' % max_iter)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "import networkx as nx\n",
        "G=nx.barabasi_albert_graph(60,41)\n",
        "pr=nx.pagerank(G,0.4)\n",
        "pr\n",
        "  \n"
      ]
    }
  ]
}